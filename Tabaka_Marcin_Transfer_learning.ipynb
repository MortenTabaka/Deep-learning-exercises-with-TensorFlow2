{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea862153",
   "metadata": {},
   "source": [
    "# Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6109a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0feb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tarfile\n",
    "# tar_train_val = tarfile.open('./data/VOCtrainval_06-Nov-2007.tar')\n",
    "# tar_train_val.extractall('./data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739bf674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classes_from_txt(file_path):\n",
    "    \n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    class_name = file_name.split('_')[0]\n",
    "    \n",
    "    df = pd.read_csv(file_path, sep='\\s+| |  ', engine='python', \n",
    "                     header=None)\n",
    "    \n",
    "    df.columns = ['file_name', class_name]\n",
    "    \n",
    "    df.loc[df[class_name]==-1, class_name] = 0\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c5541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = load_classes_from_txt('./data/VOCdevkit/VOC2007/ImageSets/Main/aeroplane_train.txt')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = os.path.basename('./data/VOCdevkit/VOC2007/ImageSets/Main/aeroplane_train.txt')\n",
    "# file_name.split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4a5688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_with_classes_in_images(folder_path, which_set='train'):\n",
    "    \n",
    "    '''\n",
    "    Returns DataFrame with class annotations for every image in chosen set.\n",
    "    \n",
    "    Args:\n",
    "        folder_path -- path to folder containing .txt files with labels\n",
    "        which_set -- 'train', 'trainval', 'val', 'test'\n",
    "    '''\n",
    "    \n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        pass\n",
    "    \n",
    "    # create dataframes with file name column \n",
    "    df_all_classes = pd.read_csv(f'{root}{which_set}.txt', header=None, dtype=str)\n",
    "    df_all_classes.columns = ['file_name']\n",
    "    \n",
    "    # loops through all file names in the folder\n",
    "    for file_name in files:\n",
    "        \n",
    "        # exclude txt files without information about class apperance in a image\n",
    "        if file_name not in ['train.txt', 'trainval.txt', 'val.txt', 'test.txt']:\n",
    "            \n",
    "            #  get information which of dataset's splits the file relates to\n",
    "            ds_part = file_name.split('_')[1]\n",
    "            \n",
    "            file_path = root + file_name\n",
    "            \n",
    "            # function for getting dataframe from txt file\n",
    "            df = load_classes_from_txt(file_path=file_path)\n",
    "         \n",
    "            # check if annotations are for images of chosen set\n",
    "            if ds_part==(which_set+'.txt'):\n",
    "                \n",
    "                # statment check if columns are equal before concatenation\n",
    "                if not df_all_classes['file_name'].astype('int').equals(df['file_name']):\n",
    "                    print('File name columns are not equal!')\n",
    "                \n",
    "                df_all_classes = pd.concat([df_all_classes, df.iloc[:, 1]], axis=1)\n",
    "            \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "\n",
    "    # get column names exluding 'file_name'\n",
    "    cols = df_all_classes.columns.tolist()[1:]\n",
    "        \n",
    "    cols.sort()\n",
    "    \n",
    "    cols.insert(0, 'file_name')\n",
    "    \n",
    "#     print(cols)\n",
    "\n",
    "    # rearrange columns order\n",
    "    df_all_classes = df_all_classes[cols]\n",
    "           \n",
    "    return df_all_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './data/VOCdevkit/VOC2007/ImageSets/Main/'\n",
    "\n",
    "df_train = get_dataframe_with_classes_in_images(folder_path, which_set='train')\n",
    "df_trainval = get_dataframe_with_classes_in_images(folder_path, which_set='trainval')\n",
    "df_val = get_dataframe_with_classes_in_images(folder_path, which_set='val')\n",
    "\n",
    "test_path = './data/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/ImageSets/Main/'\n",
    "\n",
    "df_test = get_dataframe_with_classes_in_images(test_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc8d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62782e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e4c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ec3d32",
   "metadata": {},
   "source": [
    "## Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_graph_of_images_count(dataframe):\n",
    "    \n",
    "    ax = dataframe.plot(kind='bar', figsize=(20, 15), title='Images count per class',\n",
    "                        xlabel='Class', ylabel='Count', legend=False, fontsize=12)\n",
    "    \n",
    "    ax.legend(fontsize=12)\n",
    "\n",
    "    for i in range(len(dataframe.columns)):\n",
    "        ax.bar_label(ax.containers[i], label_type='edge', rotation=90, fontsize=12, padding=3)\n",
    "\n",
    "    ax.margins(y=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcadecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train_class_count = pd.DataFrame(df_train.sum().iloc[1:], columns=['train'])\n",
    "\n",
    "df_val_class_count = pd.DataFrame(df_val.sum().iloc[1:], columns=['val'])\n",
    "\n",
    "df_test_class_count = pd.DataFrame(df_test.sum().iloc[1:], columns=['test'])\n",
    "\n",
    "# concat\n",
    "df_class_count = pd.concat([df_train_class_count, df_val_class_count, df_test_class_count], axis=1)\n",
    "\n",
    "# sum across train/val/test count\n",
    "df_class_count['total']= df_class_count.sum(axis=1).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f4663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_count = df_class_count.sort_values(by=['total'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4384833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_graph_of_images_count(df_class_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056c02bd",
   "metadata": {},
   "source": [
    "Most common class found in images by far is 'person'. Next are car, chair and dog.\n",
    "\n",
    "The least amount of images depict sheeps with only 193 images in total of around 10k of images! Other classes are also not faring better. \n",
    "\n",
    "The distribution of class across train/val/test sets is almost equal. \n",
    "E.g.: Class 'person' appear in:\n",
    "    \n",
    "    * 1025 images in train set\n",
    "    * 985 images in validation set\n",
    "    * 2007 images in test set, which consists of 50% of all images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25271f06",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f7c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:, 0].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f48d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes in image 000012.jpg\n",
    "ds = df_train.iloc[0, 1:]\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a42b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = df_train.iloc[0, 0]\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fb54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(df_train.iloc[:, 1:])\n",
    "NUM_CLASSES = len(classes)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d800a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_as_list = list(ds)\n",
    "ds_as_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(labels_list, n_classes=NUM_CLASSES):\n",
    "       \n",
    "    for i, cls in enumerate(labels_list):\n",
    "        \n",
    "        if cls == 1:\n",
    "            \n",
    "            labels_list[i] = i\n",
    "    \n",
    "    Y = tf.keras.utils.to_categorical(labels_list)\n",
    "    \n",
    "    return Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89098fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_arr = to_categorical(ds_as_list, 20)\n",
    "cat_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368fb37",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 299\n",
    "\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aac7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(file_path, label):\n",
    "    \"\"\"\n",
    "    Function that returns a tuple of normalized image array and labels array.\n",
    "    \n",
    "    Args:\n",
    "        file_path: string representing path to image\n",
    "        label: 0/1 one-dimensional array of size N_LABELS\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read an image from a file\n",
    "    image_string = tf.io.read_file(file_path)\n",
    "    \n",
    "    # Decode it into a dense vector\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n",
    "    \n",
    "    # Resize it to fixed shape\n",
    "    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n",
    "    \n",
    "    # Normalize it from [0, 255] to [0.0, 1.0]\n",
    "    image_normalized = image_resized / 255.0\n",
    "    \n",
    "    return image_normalized, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ec4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "SHUFFLE_BUFFER_SIZE = 512\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607a8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_paths_and_labels(dataframe, images_folder_path): \n",
    "    \n",
    "    '''\n",
    "    Get lists of paths to images and their corresponding labels\n",
    "    \n",
    "    Args:\n",
    "        dataframe: pandas dataframe\n",
    "        images_folder_path: path to folder with images\n",
    "    '''\n",
    "    \n",
    "    set_paths = []\n",
    "    set_labels = []\n",
    "\n",
    "    for i in range(len(dataframe)):\n",
    "\n",
    "        path = f'{images_folder_path}{dataframe.iloc[i, 0]}.jpg'\n",
    "        set_paths.append(path)\n",
    "\n",
    "        set_labels.append(list(dataframe.iloc[i, 1:]))\n",
    "    \n",
    "    return set_paths, set_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d6fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataframe, images_folder_path, is_training=True):\n",
    "    \"\"\"\n",
    "    Load and parse dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataframe: pandas dataframe\n",
    "        images_folder_path: path to folder with images\n",
    "        is_training: boolean to indicate training mode\n",
    "    \"\"\"\n",
    "    \n",
    "    filepaths, labels = get_img_paths_and_labels(dataframe, images_folder_path)\n",
    "    \n",
    "    # Create a first dataset of file paths and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
    "    \n",
    "    # Parse and preprocess observations in parallel\n",
    "    dataset = dataset.map(parse_image, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    if is_training == True:\n",
    "    \n",
    "        # This is a small dataset, only load it once, and keep it in memory.\n",
    "        dataset = dataset.cache()\n",
    "        \n",
    "        # Shuffle the data each buffer size\n",
    "        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
    "        \n",
    "    # Batch the data for multiple steps\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    # Fetch batches in the background while the model is training.\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cfa04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_images_path = './data/VOCdevkit/VOC2007/JPEGImages/'\n",
    "test_images_path = './data/VOCtest_06-Nov-2007/VOCdevkit/VOC2007/JPEGImages'\n",
    "\n",
    "# for trainval_root, _, _ in os.walk(trainval_images_path):\n",
    "#     pass\n",
    "\n",
    "# for test_root, _, _ in os.walk(test_images_path):\n",
    "#     pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bdbe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(df_train, trainval_images_path)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8ce463",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = create_dataset(df_val, trainval_images_path)\n",
    "test_ds = create_dataset(df_test, test_images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6125596",
   "metadata": {},
   "source": [
    "# Deep learning model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed1fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = tf.keras.applications.Xception(weights='imagenet',\n",
    "                                        include_top=False,\n",
    "                                        input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "conv_base.trainable = False\n",
    "print(\"weights:\", len(conv_base.weights))\n",
    "print(\"trainable_weights:\", len(conv_base.trainable_weights))\n",
    "print(\"non_trainable_weights:\", len(conv_base.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eb2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    \n",
    "    conv_base,\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    \n",
    "    layers.Dense(512, activation='relu'),\n",
    "    \n",
    "    layers.Dense(num_classes, activation='softmax', name='output')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d1b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b3ae11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                   validation_data=val_ds,\n",
    "                   epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56abb28",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8962f9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow GPU (Python 3.7)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
